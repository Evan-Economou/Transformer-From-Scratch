{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a14b7e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from jaxtyping import Float, Int\n",
    "import requests\n",
    "import unicodedata\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05314450",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "533bce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gutenberg_book(\n",
    "\tid: int|None = 84,\n",
    "\tdata_temp: Path|str = \"../../../../data/gutenberg_data\",\n",
    "\tremove_gutenberg_meta: bool = True,\n",
    ") -> str:\n",
    "\t\n",
    "\tdata_temp = Path(data_temp)\n",
    "\tdata_temp.mkdir(parents=True, exist_ok=True)\n",
    "\t\n",
    "\turl: str = f\"https://www.gutenberg.org/cache/epub/{id}/pg{id}.txt\"\n",
    "\tdata_path: Path = Path(data_temp) / f\"{id}.txt\"\n",
    "\tdata: str\n",
    "\t# read from cache if it exists\n",
    "\tif data_path.exists():\n",
    "\t\twith open(data_path, 'r', encoding='utf-8') as file:\n",
    "\t\t\tdata = file.read()\n",
    "\telse:\n",
    "\t\t# download if it doesn't exist\n",
    "\t\tresponse = requests.get(url)\n",
    "\t\tresponse.raise_for_status()  # Ensure that the download was successful\n",
    "\t\tdata = response.text\n",
    "\n",
    "\t\t# save to cache\n",
    "\t\twith open(data_path, 'w', encoding='utf-8') as file:\n",
    "\t\t\tfile.write(data)\n",
    "\n",
    "\t# remove header/footer\n",
    "\tif remove_gutenberg_meta:\n",
    "\t\tdata = '***'.join(data.split('***')[2:])\n",
    "\t\tdata = '***'.join(data.split('***')[:-1])\n",
    "\t\n",
    "\treturn data\n",
    "\n",
    "def get_many_books(\n",
    "\t\tids: list[int],\n",
    "\t\tdata_temp: Path|str = \"../data/gutenberg_data\",\n",
    "\t) -> list[list[str]]:\n",
    "\t\n",
    "\tdata: list[str] = []\n",
    "\tfor id in ids:\n",
    "\t\tprint(f\"Getting book {id}...\")\n",
    "\t\titem: str = get_gutenberg_book(id, data_temp)\n",
    "\t\tprint(f\"\\t{len(item)} characters read\")\n",
    "\t\tdata.append(item)\n",
    "\t\n",
    "\treturn data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee444a7",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b63bede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config():\n",
    "    d_model: int\n",
    "    d_vocab: int\n",
    "    d_hidden: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7e41103",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(config.d_model, config.d_hidden)\n",
    "        self.linear2 = nn.Linear(config.d_hidden, config.d_model)\n",
    "        \n",
    "\n",
    "    def forward(self, x: Float[torch.Tensor, \"seq_len d_model\"]) -> Float[torch.Tensor, \"seq_len d_model\"]:\n",
    "        x = self.linear1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff83a5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.W_qk = nn.Linear(config.d_model, config.d_model)\n",
    "        self.W_vo = nn.Linear(config.d_model, config.d_model)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "\n",
    "    def create_mask(self, n_c: int) -> torch.Tensor:\n",
    "        mask: Float[torch.Tensor, \"seq_len seq_len\"] = torch.triu(-1 * torch.inf * torch.ones(n_c, n_c), diagonal=1)\n",
    "        return mask\n",
    "\n",
    "    def forward(self, x: Float[torch.Tensor, \"seq_len d_model\"]) -> Float[torch.Tensor, \"seq_len d_model\"]:\n",
    "        #create mask, with size n_c x n_c\n",
    "        mask = self.create_mask(x.shape[0])\n",
    "\n",
    "        #compute attention scores\n",
    "        # A = softmax((X @ W_qk @ X^T) + M) @ X @ W_vo\n",
    "        A = self.softmax((self.W_qk(x)) @ x.transpose(0, -1) + mask) @ self.W_vo(x)\n",
    "        return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fd1570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(torch.nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "        self.attention_head = AttentionHead(config)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x: Float[torch.Tensor, \"seq_len d_model\"]) -> Float[torch.Tensor, \"seq_len d_model\"]:\n",
    "        return x + self.attention_head(x) + self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "590a6c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(torch.nn.Module):\n",
    "    def __init__(self, num_blocks: int, config: Config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embedding = nn.Linear(config.d_vocab, config.d_model)\n",
    "        self.blocks = nn.ModuleList([TransformerBlock(config) for _ in range(num_blocks)])\n",
    "        \n",
    "\n",
    "    def forward(self, x: Float[torch.Tensor, \"seq_len vocab\"]) -> Float[torch.Tensor, \"vocab seq_len\"]:\n",
    "        x = self.embedding(x)\n",
    "        print(\"after embedding: \",x)\n",
    "        for block in self.blocks:\n",
    "            x = block.forward(x)\n",
    "            print(\"after forward: \",x)\n",
    "        x = (x @ self.embedding.weight).T\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2f4b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer():\n",
    "    def __init__(self, raw_data: str):\n",
    "        self.raw_data = raw_data \n",
    "        self.vocab_size = None\n",
    "        self.vocab = None\n",
    "        self.vocab_inverse = None\n",
    "        \n",
    "    def process_raw_data(self, text: str, \n",
    "                        allowed_punctuation: str = \"-.,;:!?()\\\"\" + \"\".join(str(x) for x in range(10)),\n",
    "                        punctuation_convert: dict[str,str] = {'â€”': '-'}\n",
    "                        ) -> str:\n",
    "        for char, replacement in punctuation_convert.items():\n",
    "            text = text.replace(char, replacement)\n",
    "              \n",
    "        text = '\\n'.join(\n",
    "                    line \n",
    "                    for line in text.split('\\n')\n",
    "                    if '.jpg' not in line\n",
    "                )\n",
    "        \n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "\n",
    "        # Encode to ASCII bytes, then decode back to string, ignoring errors (removing any non-ascii characters)\n",
    "        text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "        # remove newlines and tabs\n",
    "        text = text.replace('\\n', ' ').replace('\\t', ' ')\n",
    "\n",
    "        for char in allowed_punctuation:\n",
    "            text = text.replace(char, f' {char} ')\n",
    "              \n",
    "        text = text.strip()\n",
    "\n",
    "        # remove multiple spaces\n",
    "        while '  ' in text:\n",
    "            text = text.replace('  ', ' ')\n",
    "\n",
    "        text = ''.join((char if (char.isalnum() or char in allowed_punctuation or char == ' ') else ' ') for char in text)\n",
    "        \n",
    "        text = text.lower()\n",
    "\n",
    "        text = text.strip()\n",
    "\n",
    "        return text\n",
    "    \n",
    "    def tokenize(self, \n",
    "        text: str,\n",
    "        process: bool = False,\n",
    "    ):\n",
    "        if process:\n",
    "            text = self.process_raw_data(text)\n",
    "        tokenized_text = text.split(' ')\n",
    "\n",
    "        vocab_counts: Counter[str] = Counter(tokenized_text).most_common()\n",
    "        self.vocab_size: int = len(vocab_counts)\n",
    "        self.vocab: list[str] = [token for token, count in vocab_counts]\n",
    "        self.vocab_inverse: dict[int: str] = {key: value for key, value in (self.vocab, range(0, self.vocab_size))}\n",
    "        \n",
    "    def encode(self, data: str) -> list[int]:\n",
    "        return [self.vocab_inverse[word] for word in data]\n",
    "    \n",
    "    def decode(self, tokens: list[int]) -> str:\n",
    "        return ''.join(self.vocab[token] for token in tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f0dc71",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a8979a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 16])\n"
     ]
    }
   ],
   "source": [
    "# Attention head test\n",
    "x: Float[torch.Tensor, \"seq_len d_model\"] = torch.ones(5, 16)\n",
    "config = Config(d_model=16, d_vocab=1000, d_hidden=64)\n",
    "attention_head: AttentionHead = AttentionHead(config)\n",
    "output: Float[torch.Tensor, \"seq_len d_model\"] = attention_head.forward(x)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d392391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after embedding:  tensor([ 0.8426, -0.9188, -1.1098,  1.3780,  0.6834, -0.5027, -0.0112, -0.8434,\n",
      "        -0.8474,  0.7470, -0.1307,  0.0880,  0.1524, -0.3429,  0.1422, -0.0159],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "after forward:  tensor([ 1.2053, -1.4417, -1.2446,  1.3650,  0.7479, -0.3113, -0.1083, -1.2168,\n",
      "        -0.8922,  0.6577, -0.2969,  0.0850,  0.2383, -0.4125,  0.2404, -0.0653],\n",
      "       grad_fn=<AddBackward0>)\n",
      "after forward:  tensor([ 0.5146, -1.4184, -1.1799,  1.7781,  0.4559, -0.5912,  0.3941, -1.3317,\n",
      "        -0.3776,  0.7924, -0.1868,  0.0027, -0.0444, -0.0522, -0.2250, -0.1987],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "after embedding:  tensor([ 0.8426, -0.9188, -1.1098,  1.3780,  0.6834, -0.5027, -0.0112, -0.8434,\n",
      "        -0.8474,  0.7470, -0.1307,  0.0880,  0.1524, -0.3429,  0.1422, -0.0159],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "after forward:  tensor([ 1.2053, -1.4417, -1.2446,  1.3650,  0.7479, -0.3113, -0.1083, -1.2168,\n",
      "        -0.8922,  0.6577, -0.2969,  0.0850,  0.2383, -0.4125,  0.2404, -0.0653],\n",
      "       grad_fn=<AddBackward0>)\n",
      "after forward:  tensor([ 0.5146, -1.4184, -1.1799,  1.7781,  0.4559, -0.5912,  0.3941, -1.3317,\n",
      "        -0.3776,  0.7924, -0.1868,  0.0027, -0.0444, -0.0522, -0.2250, -0.1987],\n",
      "       grad_fn=<AddBackward0>)\n",
      "<class 'torch.Size'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the whole thing\n",
    "config = Config(d_model=16, d_vocab=1000, d_hidden=64)\n",
    "transformer = Transformer(num_blocks=2, config=config)\n",
    "x = torch.ones(config.d_vocab, dtype=torch.float)\n",
    "y: Float[torch.Tensor, \"vocab seq_len\"] = transformer(x)\n",
    "# print(y.shape)\n",
    "# print(y)\n",
    "# print(x)\n",
    "\n",
    "#TODO run the (initially randomly distributed) code to predict some nonsense and print intermediate values\n",
    "def generate_words(transformer: Transformer, num_words: int, input_tokenized: list[int]) -> list[int]:\n",
    "    print(input_tokenized)\n",
    "    output_tokenized = transformer.forward(input_tokenized)\n",
    "    print(type(output.shape))\n",
    "    return []\n",
    "\n",
    "generate_words(transformer,1,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ba5bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bf6f7f1",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85cedf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model: Transformer,\n",
    "    loss: torch.nn.CrossEntropyLoss = nn.CrossEntropyLoss(),\n",
    "    lr: Float = 1e-3,\n",
    "    epochs: Int = 1\n",
    "    ):\n",
    "    optimizer: torch.optim.SGD = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    string_data = get_many_books(ids=range(10,15), data_temp=\"./data/gutenberg_data\")\n",
    "    tokenized_string_data = [x for i in string_data]\n",
    "    \n",
    "    labels = {}\n",
    "    int_labels = []\n",
    "    for i in range(len(string_data)):\n",
    "        labels[i] = string_data[i]\n",
    "        int_labels.append(i)\n",
    "    \n",
    "    training_data = torch.tensor(int_labels)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(training_data)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89cd1298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting book 10...\n",
      "\t4432261 characters read\n",
      "Getting book 11...\n",
      "\t148062 characters read\n",
      "Getting book 12...\n",
      "\t168390 characters read\n",
      "Getting book 13...\n",
      "\t34579 characters read\n",
      "Getting book 14...\n",
      "\t1951150 characters read\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Long and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m config: Config = Config(d_model=\u001b[32m16\u001b[39m, d_vocab=\u001b[32m1000\u001b[39m, d_hidden=\u001b[32m64\u001b[39m)\n\u001b[32m      2\u001b[39m model = Transformer(num_blocks=\u001b[32m2\u001b[39m, config=config)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, loss, lr, epochs)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m     21\u001b[39m     optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\narwh\\OneDrive\\Desktop\\Transformer-From-Scratch\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\narwh\\OneDrive\\Desktop\\Transformer-From-Scratch\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Float[torch.Tensor, \u001b[33m\"\u001b[39m\u001b[33mseq_len vocab\u001b[39m\u001b[33m\"\u001b[39m]) -> Float[torch.Tensor, \u001b[33m\"\u001b[39m\u001b[33mvocab seq_len\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks:\n\u001b[32m     12\u001b[39m         x = block.forward(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\narwh\\OneDrive\\Desktop\\Transformer-From-Scratch\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\narwh\\OneDrive\\Desktop\\Transformer-From-Scratch\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\narwh\\OneDrive\\Desktop\\Transformer-From-Scratch\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 must have the same dtype, but got Long and Float"
     ]
    }
   ],
   "source": [
    "config: Config = Config(d_model=16, d_vocab=1000, d_hidden=64)\n",
    "model = Transformer(num_blocks=2, config=config)\n",
    "train_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decoding-gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
